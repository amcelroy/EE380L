{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mimicloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8044485634847081"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class confusion_matrix_metrics(object):\n",
    "    def __init__(self,M):\n",
    "        self.M = M\n",
    "        self.TP = M[0,0]\n",
    "        self.FN = M[0,1]\n",
    "        self.FP = M[1,0]\n",
    "        self.TN = M[1,1]\n",
    "    \n",
    "    def sensitivity(self):\n",
    "        return self.TP/(self.TP + self.FN)\n",
    "    def specificity(self):\n",
    "        return self.TN/(self.TN + self.FP)\n",
    "    def precision(self):\n",
    "        return self.TP/(self.TP + self.FP)\n",
    "    def negative_predictive_value(self):\n",
    "        return self.TN/(self.TN + self.FN)\n",
    "    def miss_rate(self):\n",
    "        return 1 - self.sensitivity()\n",
    "    def fall_out(self):\n",
    "        return 1 - self.specificity()\n",
    "    def false_discovery(self):\n",
    "        return 1 - self.precision()\n",
    "    def false_omission(self):\n",
    "        return 1 - self.negative_predictive_value()\n",
    "    def threat_score(self):\n",
    "        return self.TP/(self.TP + self.FN + self.FP)\n",
    "    def accuracy(self):\n",
    "        return (self.TP + self.TN)/(self.TP + self. TN + self.FP + self.FN)\n",
    "    def balanced_accuracy(self):\n",
    "        return self.sensitivity()/2 + self.specificity()/2\n",
    "    \n",
    "filepath = 'mimic_dataset.csv'\n",
    "loader = MIMICLoader()\n",
    "df = loader.load(filepath)\n",
    "df1 = df[df.hospital_expire_flag == 1]\n",
    "df2 = df[df.hospital_expire_flag == 0]\n",
    "df2 = df2.sample(n=len(df1))\n",
    "df3 = df1.append(df2)\n",
    "y = df3.hospital_expire_flag\n",
    "X = df3.drop(columns=['hospital_expire_flag'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.8,random_state=42)\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=1000,learning_rate=0.5)\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_test,y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8396663577386468"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=1000,criterion='gini')\n",
    "clf.fit(X_train,y_train)\n",
    "yhat = clf.predict(X_test)\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('mimic_dataset.csv')\n",
    "df.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "df = df[df['patientweight'].notna()]\n",
    "fillcols = {'hospital_expire_flag':0,'age':df.age.mean(),'NumDrugs':0,'num_procedures':0,'curr_service':0,'num_serv':0,'num_transfers':0,'curr_careunit':0,\\\n",
    "            'avg_los':df.avg_los.mean(),'tot_los':df.tot_los.mean(),'num_unique_reads':df.num_unique_reads.mean(),\\\n",
    "           'total_reads':df.total_reads.mean(),'uinique_caregivers':df.uinique_caregivers.mean(),'total_icd9':df.total_icd9.mean(),'total_icu_hours':0,\\\n",
    "           'avg_icu_hours':0,'total_icu_stays':0,'avg_num_drug_administered':0,'max_drug_administered':0,'total_input_drugs':0,'tot_routes':0,\\\n",
    "           'tot_org':0,'org_name':0,'org_itemid':0}\n",
    "df.fillna(value=fillcols,inplace=True)\n",
    "serv = df.curr_service.unique()\n",
    "care = df.curr_careunit.unique()\n",
    "org = df.org_name.unique()\n",
    "\n",
    "def replace_stuff(s):\n",
    "    new_dic = {}\n",
    "    i = 1\n",
    "    for j in s:\n",
    "        if j != 0:\n",
    "            new_dic[j] = i\n",
    "            i +=1\n",
    "    return new_dic\n",
    "df.replace({'curr_service':replace_stuff(serv),'curr_careunit':replace_stuff(care),'org_name':replace_stuff(org)},inplace=True)\n",
    "df = df.apply(np.int64)\n",
    "df = df.drop(columns=['subject_id','hadm_id','total_input_drugs','total_icu_hours','max_drug_administered','org_name'])\n",
    "df1 = df[df.hospital_expire_flag == 1]\n",
    "df2 = df[df.hospital_expire_flag == 0]\n",
    "df2 = df2.sample(n=len(df1))\n",
    "df3 = df1.append(df2)\n",
    "X = df3.drop(columns=['hospital_expire_flag'])\n",
    "y = df3.hospital_expire_flag\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "      <th>age</th>\n",
       "      <th>NumDrugs</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>curr_service</th>\n",
       "      <th>num_serv</th>\n",
       "      <th>num_transfers</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_icu_hours</th>\n",
       "      <th>total_icu_stays</th>\n",
       "      <th>avg_num_drug_administered</th>\n",
       "      <th>max_drug_administered</th>\n",
       "      <th>total_input_drugs</th>\n",
       "      <th>tot_routes</th>\n",
       "      <th>patientweight</th>\n",
       "      <th>tot_org</th>\n",
       "      <th>org_name</th>\n",
       "      <th>org_itemid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17575</td>\n",
       "      <td>187131</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>TRAUM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.461538</td>\n",
       "      <td>93.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>STAPHYLOCOCCUS, COAGULASE NEGATIVE</td>\n",
       "      <td>80155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51820</td>\n",
       "      <td>148131</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>MED</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>GRAM NEGATIVE ROD(S)</td>\n",
       "      <td>80058.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25835</td>\n",
       "      <td>162690</td>\n",
       "      <td>0</td>\n",
       "      <td>305</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MED</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>POSITIVE FOR METHICILLIN RESISTANT STAPH AUREUS</td>\n",
       "      <td>80293.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>71915</td>\n",
       "      <td>198577</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MED</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>368</td>\n",
       "      <td>138061</td>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MED</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.600000</td>\n",
       "      <td>116.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61200</td>\n",
       "      <td>61200</td>\n",
       "      <td>5298</td>\n",
       "      <td>183445</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CSURG</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>32.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61201</td>\n",
       "      <td>61201</td>\n",
       "      <td>13964</td>\n",
       "      <td>175807</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NSURG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61202</td>\n",
       "      <td>61202</td>\n",
       "      <td>11789</td>\n",
       "      <td>145800</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>CSURG</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.647059</td>\n",
       "      <td>78.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ESCHERICHIA COLI</td>\n",
       "      <td>80002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61203</td>\n",
       "      <td>61203</td>\n",
       "      <td>17022</td>\n",
       "      <td>116381</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NSURG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.857143</td>\n",
       "      <td>118.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61204</td>\n",
       "      <td>61204</td>\n",
       "      <td>24734</td>\n",
       "      <td>146651</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MED</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61205 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  subject_id  hadm_id  hospital_expire_flag  age  NumDrugs  \\\n",
       "0               0       17575   187131                     0   18       NaN   \n",
       "1               1       51820   148131                     0   89      20.0   \n",
       "2               2       25835   162690                     0  305      53.0   \n",
       "3               3       71915   198577                     0   89      22.0   \n",
       "4               4         368   138061                     0  302      79.0   \n",
       "...           ...         ...      ...                   ...  ...       ...   \n",
       "61200       61200        5298   183445                     0   88       NaN   \n",
       "61201       61201       13964   175807                     0   88       NaN   \n",
       "61202       61202       11789   145800                     0   88       NaN   \n",
       "61203       61203       17022   116381                     0   88       NaN   \n",
       "61204       61204       24734   146651                     0   88       NaN   \n",
       "\n",
       "       num_procedures curr_service  num_serv  num_transfers  ...  \\\n",
       "0                 9.0        TRAUM       1.0            1.0  ...   \n",
       "1                 2.0          MED       1.0            1.0  ...   \n",
       "2                 NaN          MED       1.0            2.0  ...   \n",
       "3                 NaN          MED       1.0            3.0  ...   \n",
       "4                 1.0          MED       1.0            3.0  ...   \n",
       "...               ...          ...       ...            ...  ...   \n",
       "61200             5.0        CSURG       2.0            4.0  ...   \n",
       "61201             NaN        NSURG       1.0            2.0  ...   \n",
       "61202             6.0        CSURG       2.0            3.0  ...   \n",
       "61203             1.0        NSURG       1.0            2.0  ...   \n",
       "61204             NaN          MED       1.0            1.0  ...   \n",
       "\n",
       "      avg_icu_hours  total_icu_stays  avg_num_drug_administered  \\\n",
       "0               3.0              1.0                  25.461538   \n",
       "1               2.0              1.0                        NaN   \n",
       "2               1.0              1.0                        NaN   \n",
       "3               1.0              1.0                        NaN   \n",
       "4               2.0              1.0                  34.600000   \n",
       "...             ...              ...                        ...   \n",
       "61200           1.0              1.0                  10.333333   \n",
       "61201           1.0              1.0                   6.500000   \n",
       "61202           2.0              1.0                  14.647059   \n",
       "61203           3.0              1.0                  34.857143   \n",
       "61204           1.0              1.0                   7.500000   \n",
       "\n",
       "       max_drug_administered  total_input_drugs  tot_routes  patientweight  \\\n",
       "0                       93.0              331.0         2.0            NaN   \n",
       "1                        NaN                NaN         NaN           82.0   \n",
       "2                        NaN                NaN         NaN           42.7   \n",
       "3                        NaN                NaN         NaN           50.4   \n",
       "4                      116.0              173.0         3.0            NaN   \n",
       "...                      ...                ...         ...            ...   \n",
       "61200                   32.0              124.0         3.0            NaN   \n",
       "61201                   11.0               13.0         2.0            NaN   \n",
       "61202                   78.0              249.0         3.0            NaN   \n",
       "61203                  118.0              244.0         3.0            NaN   \n",
       "61204                   12.0               15.0         1.0            NaN   \n",
       "\n",
       "       tot_org                                         org_name  org_itemid  \n",
       "0          1.0               STAPHYLOCOCCUS, COAGULASE NEGATIVE     80155.0  \n",
       "1          2.0                             GRAM NEGATIVE ROD(S)     80058.0  \n",
       "2          4.0  POSITIVE FOR METHICILLIN RESISTANT STAPH AUREUS     80293.0  \n",
       "3          0.0                                              NaN         NaN  \n",
       "4          0.0                                              NaN         NaN  \n",
       "...        ...                                              ...         ...  \n",
       "61200      NaN                                              NaN         NaN  \n",
       "61201      0.0                                              NaN         NaN  \n",
       "61202      2.0                                 ESCHERICHIA COLI     80002.0  \n",
       "61203      NaN                                              NaN         NaN  \n",
       "61204      0.0                                              NaN         NaN  \n",
       "\n",
       "[61205 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('mimic_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.37921022067364"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.patientweight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28709055876685935"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AdaBoostClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "yhat = model.predict(X_test)\n",
    "M = confusion_matrix(y_true=y_test,y_pred=yhat)\n",
    "metrics = confusion_matrix_metrics(M)\n",
    "metrics.sensitivity()\n",
    "metrics.specificity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6318092812425977"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.balanced_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df.hospital_expire_flag == 1]\n",
    "df2 = df[df.hospital_expire_flag == 0]\n",
    "df2 = df2.sample(n=len(df1))\n",
    "df3 = df1.append(df2)\n",
    "X = df3.drop(columns=['hospital_expire_flag'])\n",
    "y = df3.hospital_expire_flag\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaBoostClassifier(n_estimators=1000,learning_rate=0.5)\n",
    "model.fit(X_train1,y_train1)\n",
    "yhat1 = model.predict(X_test1)\n",
    "yhat = model.predict(X_test)\n",
    "M1 = confusion_matrix(y_true=y_test1,y_pred=yhat1)\n",
    "M = confusion_matrix(y_test,yhat)\n",
    "metrics = confusion_matrix_metrics(M)\n",
    "metrics1 = confusion_matrix_metrics(M1)\n",
    "metrics.balanced_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LogisticRegression()\n",
    "model1.fit(X_train1,y_train1)\n",
    "yhat1 = model1.predict(X_test1)\n",
    "yhat = model1.predict(X_test)\n",
    "M1 = confusion_matrix(y_true=y_test1,y_pred=yhat1)\n",
    "M = confusion_matrix(y_test,yhat)\n",
    "metrics = confusion_matrix_metrics(M)\n",
    "metrics1 = confusion_matrix_metrics(M1)\n",
    "metrics.balanced_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,18))\n",
    "sns.heatmap(df.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = RandomForestClassifier(n_estimators=1000,criterion='gini')\n",
    "model1.fit(X_train1,y_train1)\n",
    "yhat1 = model1.predict(X_test1)\n",
    "yhat = model1.predict(X_test)\n",
    "M1 = confusion_matrix(y_true=y_test1,y_pred=yhat1)\n",
    "M = confusion_matrix(y_test,yhat)\n",
    "metrics = confusion_matrix_metrics(M)\n",
    "metrics1 = confusion_matrix_metrics(M1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.sensitivity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.specificity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.negative_predictive_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.balanced_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "class StumpLearner(object):\n",
    "    def __init__(self):\n",
    "        self.direction = 1\n",
    "        self.node_feat_index = None\n",
    "        self.thresh = None\n",
    "        self.weight = None\n",
    "\n",
    "class AdaBoost(object):\n",
    "\n",
    "    def __init__(self, T):\n",
    "        self.T = T\n",
    "\n",
    "    def fit(self, X, y,random_selection=5):\n",
    "        n_observations, n_feats = X.shape\n",
    "        D = 1/n_observations*np.ones(n_observations)\n",
    "        self.random_selection = random_selection\n",
    "        self.classifier = []\n",
    "\n",
    "        for _ in range(self.T):\n",
    "            classifier = StumpLearner()\n",
    "            min_err = float('inf')\n",
    "\n",
    "            # pick random subset\n",
    "            feats = np.random.randint(0,n_feats,self.random_selection)\n",
    "\n",
    "            for feat_i in feats:\n",
    "                thresholds = np.unique(X[:,feat_i])\n",
    "\n",
    "                # bin thresholds, make threshold matrix from beginning?\n",
    "                for threshold in thresholds:\n",
    "                    direction = 1\n",
    "                    prediction = np.ones(len(y))\n",
    "                    prediction[X[:,feat_i] < threshold] = -1\n",
    "                    #error = sum(D[y != prediction])\n",
    "                    error = speedy_sum(D,y,prediction)\n",
    "\n",
    "                    if error > 1/2:\n",
    "                        error = 1-error\n",
    "                        direction = -1\n",
    "                    if error<min_err:\n",
    "                        classifier.direction = direction\n",
    "                        classifier.thresh = threshold\n",
    "                        classifier.node_feat_index = feat_i\n",
    "                        min_err = error\n",
    "\n",
    "            classifier.weight = np.float(1/2)*np.log(1/error - 1)\n",
    "            prediction = np.ones(len(y))\n",
    "            prediction[(classifier.direction * X[:, classifier.node_feat_index] < classifier.direction * classifier.thresh)] = -1\n",
    "            D = D*np.exp(-classifier.weight * y * prediction)\n",
    "            D = D/np.sum(D)\n",
    "            self.classifier.append(classifier)\n",
    "\n",
    "    def predict(self,X):\n",
    "        n_observations = X.shape[0]\n",
    "        y_hat = np.zeros((n_observations,1))\n",
    "        for WL in self.classifier:\n",
    "            prediction = np.ones(np.shape(y_hat))\n",
    "            prediction[(WL.direction * X[:, WL.node_feat_index] < WL.direction * WL.thresh)] = -1\n",
    "            y_hat += WL.weight*prediction\n",
    "\n",
    "        return np.sign(y_hat).flatten()\n",
    "\n",
    "@jit\n",
    "def speedy_sum(D,p,y):\n",
    "    return np.sum(D[y != p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(yte,yhat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MIMICLoader:\n",
    "    def load(self, path=''):\n",
    "        df = pd.read_csv(path)\n",
    "        df = df[df['patientweight'].notna()]\n",
    "        fillcols = {'hospital_expire_flag': 0, 'age': df.age.mean(), 'NumDrugs': 0, 'num_procedures': 0,\n",
    "                    'curr_service': 0, 'num_serv': 0, 'num_transfers': 0, 'curr_careunit': 0, \\\n",
    "                    'avg_los': df.avg_los.mean(), 'tot_los': df.tot_los.mean(),\n",
    "                    'num_unique_reads': df.num_unique_reads.mean(), \\\n",
    "                    'total_reads': df.total_reads.mean(), 'uinique_caregivers': df.uinique_caregivers.mean(),\n",
    "                    'total_icd9': df.total_icd9.mean(), 'total_icu_hours': 0, \\\n",
    "                    'avg_icu_hours': 0, 'total_icu_stays': 0, 'avg_num_drug_administered': 0,\n",
    "                    'max_drug_administered': 0, 'total_input_drugs': 0, 'tot_routes': 0, \\\n",
    "                    'tot_org': 0, 'org_name': 0, 'org_itemid': 0}\n",
    "        df.fillna(value=fillcols,inplace=True)\n",
    "        return df\n",
    "\n",
    "    def getDeceased(self, data=pd.DataFrame, number=None):\n",
    "        dead = data.loc[data['hospital_expire_flag'] == 1]\n",
    "        dead = dead.drop(columns='hospital_expire_flag')\n",
    "\n",
    "        if(number):\n",
    "            indicies = np.arange(0, number)\n",
    "            random.shuffle(indicies)\n",
    "            dead = dead.iloc[indicies]\n",
    "\n",
    "        return dead\n",
    "\n",
    "    def getLiving(self, data=pd.DataFrame, number=None):\n",
    "        living = data.loc[data['hospital_expire_flag'] == 0]\n",
    "        living = living.drop(columns='hospital_expire_flag')\n",
    "\n",
    "        if(number):\n",
    "            indicies = np.arange(0, number)\n",
    "            random.shuffle(indicies)\n",
    "            living = living.iloc[indicies]\n",
    "\n",
    "        return living\n",
    "\n",
    "    def train_test_split(self, data=pd.DataFrame, train_size=.8, kfolds=5, rand_seed=42, reduced=False):\n",
    "        '''\n",
    "        Loads the MIMIC csv at the path. Returns a tuple of:\n",
    "            array of indicies for k-fold training data location\n",
    "            array of indicies for k-fold testing data location\n",
    "            array of indicies for validation data location\n",
    "        Note, the validation data is indexed BEFORE doing K-Folds, so there is\n",
    "        no overlap of the validation indexes with k-folds.\n",
    "        :param data: Pandas dataframe of the MIMIC data\n",
    "        :param train_size: percent of data to put in the training / validation\n",
    "        :param kfolds: Number of folds\n",
    "        :param rand_seed: Shuffle seed\n",
    "        :param reduced: If true, uses only 10% of the data, useful for testing\n",
    "        :return:\n",
    "        '''\n",
    "        rows = len(data.index)\n",
    "\n",
    "        if (reduced):\n",
    "            rows = int(rows * .1)\n",
    "            data = data[:rows]\n",
    "\n",
    "        indicies = np.arange(start=0, stop=len(data.index), step=1)\n",
    "        random.seed(rand_seed)\n",
    "        random.shuffle(indicies)\n",
    "\n",
    "        train_length = int(len(indicies) * train_size)\n",
    "        train_index = indicies[:train_length]\n",
    "        val_index = indicies[train_length:]\n",
    "\n",
    "        train_set = []\n",
    "        test_set = []\n",
    "\n",
    "        fold_length = int(train_length / kfolds)\n",
    "        for i in range(kfolds):\n",
    "            train_index_np = np.array(train_index)\n",
    "            test = train_index_np[i * fold_length:(i + 1) * fold_length]\n",
    "            train = np.delete(train_index_np, train_index_np[i * fold_length:(i + 1) * fold_length])\n",
    "            train_set.append(train)\n",
    "            test_set.append(test)\n",
    "\n",
    "        return train_set, test_set, val_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ml = MIMICLoader()\n",
    "data = ml.load('mimic_dataset.csv')\n",
    "kfolds_train, kfolds_test, validation = \\\n",
    "    ml.train_test_split(data, train_size=.8, kfolds=5, rand_seed=42, reduced=True)\n",
    "\n",
    "living = ml.getLiving(data, number=60)\n",
    "dead = ml.getDeceased(data, number=60)\n",
    "\n",
    "train, test, val = ml.train_test_split(living)\n",
    "\n",
    "x = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
